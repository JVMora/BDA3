{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6440ba18-b42e-4454-b6bb-0bbbfc395806",
   "metadata": {},
   "source": [
    "**10.** Non-Bayesian inference: replicate the analysis of the bioassay example in Section 3.7\n",
    "using non-Bayesian inference. This problem does not have a unique answer, so be clear\n",
    "on what methods you are using.\n",
    "\n",
    "**(a)** Construct an ‘estimator’ of $(α, β)$; that is, a function whose input is a dataset, $(x, n, y)$,\n",
    "and whose output is a point estimate $(\\hat{\\alpha}, \\hat{\\beta})$. Compute the value of the estimate for\n",
    "the data given in Table 5.2.\n",
    "\n",
    "**(b)** The bias and variance of this estimate are functions of the true values of the parameters\n",
    "$(α, β)$ and also of the sampling distribution of the data, given $α$, $β$. Assuming the\n",
    "binomial model, estimate the bias and variance of your estimator.\n",
    "\n",
    "**(c)** Create approximate 95% confidence intervals for $α$, $β$, and the LD50 based on asymptotic\n",
    "theory and the estimated bias and variance.\n",
    "\n",
    "**(d)** Does the inaccuracy of the normal approximation for the posterior distribution (compare\n",
    "Figures 3.3 and 4.1) cast doubt on the coverage properties of your confidence\n",
    "intervals in (c)? If so, why?\n",
    "\n",
    "**(e)** Create approximate 95% confidence intervals for $α$, $β$, and the LD50 using the jackknife\n",
    "or bootstrap (see Efron and Tibshirani, 1993).\n",
    "\n",
    "**(f)** Compare your 95% intervals for the LD50 in (c) and (e) to the posterior distribution\n",
    "displayed in Figure 3.4 and the posterior distribution based on the normal approximation,\n",
    "displayed in 4.2b. Comment on the similarities and differences among the four\n",
    "intervals. Which do you prefer as an inferential summary about the LD50? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeffdeae-25e0-4aa3-8ec0-28f6e1267d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from more_itertools import flatten\n",
    "import scipy.optimize\n",
    "from firthlogist import FirthLogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a7e0258-b26d-4800-8710-1ccd3931bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'x': [-0.86, -0.30, -0.05, 0.73], 'n': [5, 5, 5, 5], 'y': [0, 1, 3, 5]})\n",
    "data = data.assign(w = data['y'] / data['n'])\n",
    "data_ext = pd.DataFrame({'y': [0,0,0,0,0,1,0,0,0,0,1,1,1,0,0,1,1,1,1,1],\n",
    "                         'x': np.repeat([-0.86, -0.30, -0.05, 0.73], 5)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcdf865-5358-4d6d-8f14-10c10cf366d1",
   "metadata": {},
   "source": [
    "#### Fit with ordinary logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91f9ad4d-bfc4-462e-92a3-ce8146eb7b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   20\n",
      "Model:                            GLM   Df Residuals:                       18\n",
      "Model Family:                Binomial   Df Model:                            1\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -5.8944\n",
      "Date:                Tue, 30 Aug 2022   Deviance:                       11.789\n",
      "Time:                        15:00:07   Pearson chi2:                     10.4\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):             0.5447\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.8466      1.019      0.831      0.406      -1.151       2.844\n",
      "x              7.7488      4.873      1.590      0.112      -1.801      17.299\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "fit = smf.glm(\"y ~ x\", data = data_ext, family=sm.families.Binomial()).fit()\n",
    "print(fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f30eacc1-b453-4ab6-ab74-8ed9e7f5724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_hat = [*list(fit.params), -fit.params[0] / fit.params[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069fd83d-46a1-4d7f-99e9-9ce27b67b00c",
   "metadata": {},
   "source": [
    "#### Normal approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f05fc83-1e34-4734-ab92-886bb92e2b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               2.5%      97.5%\n",
      "Intercept  0.159223   1.533938\n",
      "x          4.462240  11.035394\n"
     ]
    }
   ],
   "source": [
    "ci = fit.conf_int(alpha = 0.5).rename(columns = {0: '2.5%', 1: '97.5%'})\n",
    "print(ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216d2d2d-3a35-45b3-a5c3-3f6c45509cfc",
   "metadata": {},
   "source": [
    "#### Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3245e725-6ae6-4794-87f1-6f84c90087a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 1000\n",
    "n = data_ext.shape[0]\n",
    "theta_star = np.zeros((B, 3))\n",
    "for b in range(B):\n",
    "    ind = np.random.choice(np.arange(n), size = n, replace = True)\n",
    "    data_i = data_ext.loc[ind]\n",
    "    fit = FirthLogisticRegression(max_iter = 150)\n",
    "    fit.fit(data_i['x'].to_numpy().reshape(-1, 1), data_i['y'])\n",
    "    theta_star[b, :] = [fit.intercept_, *fit.coef_, *-fit.intercept_ / fit.coef_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14cd9022-9df8-4c2d-bce5-13770132ed43",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = (theta_star - theta_hat).mean(axis = 0)\n",
    "Std = np.std(theta_star, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adc7e6ce-35e1-4502-ae14-a8ebaf138053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           |    2.5%    |      97.5%      \n",
      "****************************************\n",
      "intercept  |   -0.962   |      2.945      \n",
      "x          |   3.065    |      15.405     \n",
      "LD50       |   -0.325   |      0.215      \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n{:^10} | {:^10} | {:^16}\".format(\"\", \"2.5%\", \"97.5%\"))\n",
    "print(\"*\"*40)\n",
    "for i, label in zip(range(3), ('intercept', 'x', 'LD50')):\n",
    "    boot_ci = np.quantile(theta_star[:, i], q = [0.025, 0.975], axis = 0)\n",
    "    print(\"{:<10} | {:^10} | {:^16}\".format(label, round(boot_ci[0], 3), round(boot_ci[1], 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74274956-e577-4412-9a94-9ff370f7b66c",
   "metadata": {},
   "source": [
    "#### Normal approximation for the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb58077f-3bf2-4484-a084-67a79c0e1575",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ext.insert(1, 'dummy', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51fbbc06-7f6c-443a-b68d-5798f7fd476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_extended(beta, y, x):\n",
    "    return -((-np.log(1 + np.exp(np.dot(x, beta)))).sum() + (y*(np.dot(x, beta))).sum())\n",
    "\n",
    "def logistic_aggregated(w, df):\n",
    "    z = w[0] + w[1] * df['x'].values\n",
    "    return -np.sum(df['y'].values * z - df['n'].values * np.log1p(np.exp(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee717bd1-4e23-412b-80c1-2ee4699c0994",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_start = [0, 0]\n",
    "mle_ext = scipy.optimize.minimize(logistic_extended, theta_start, args=(data_ext['y'], data_ext.loc[:, 'dummy':]), method='BFGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87922b03-a964-4fba-b999-a3497cef6d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: 5.894441638970639\n",
      " hess_inv: array([[ 0.96949024,  3.4468913 ],\n",
      "       [ 3.4468913 , 23.51510283]])\n",
      "      jac: array([ 5.48362732e-06, -2.38418579e-07])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 42\n",
      "      nit: 13\n",
      "     njev: 14\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([0.84658517, 7.74883075])\n"
     ]
    }
   ],
   "source": [
    "mle = scipy.optimize.minimize(logistic_aggregated, theta_start, args=(data))\n",
    "print(mle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d55962e-7b39-4219-ae7f-d1f7e9274cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SE = np.sqrt(np.diag(mle.hess_inv))\n",
    "ci_norm_post = [mle.x - 1.96 * SE, mle.x + 1.96 * SE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47377892-b41b-4bb5-bc05-74834f2fa947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           |    2.5%    |      97.5%      \n",
      "****************************************\n",
      "alpha      |   -1.083   |      2.776      \n",
      "beta       |   -1.756   |      17.253     \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n{:^10} | {:^10} | {:^16}\".format(\"\", \"2.5%\", \"97.5%\"))\n",
    "print(\"*\"*40)\n",
    "for i, label in zip(range(2), ('alpha', 'beta')):\n",
    "    print(\"{:<10} | {:^10} | {:^16}\".format(label, round(ci_norm_post[0][i], 3), round(ci_norm_post[1][i], 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4faf39-de0a-4248-907a-935c85a319f4",
   "metadata": {},
   "source": [
    "#### Posterior directly by sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9531fbac-07d8-480a-8922-fd6016d65bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.linspace(-4, 8, 50)\n",
    "B = np.linspace(-10, 40, 50)\n",
    "cA = np.repeat(A, len(B))\n",
    "cB = np.repeat(B, len(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1eaec559-f45a-4cf1-905a-d7a4595c646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logl(df, a, b):\n",
    "    return df['y'].values * (a + b * df['x'].values) - df['n'] * np.log1p(np.exp(a + b * df['x'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27be5533-2de1-4420-aa20-fdd94ecf4425",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamp = 1000\n",
    "p = [np.exp(np.sum(logl(data, a, b))) for a in A for b in B]\n",
    "samp_indices = np.random.choice(np.arange(len(p)), size = nsamp, replace = True, p = p / np.sum(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5dcbbb6-b9ee-432e-b8c9-6dfda62b4a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_A = cA[samp_indices[:nsamp]]\n",
    "samp_B = cB[samp_indices[:nsamp]]\n",
    "samp_A = samp_A + np.random.uniform((A[0] - A[1])/2, (A[1] - A[0])/2, size = nsamp)\n",
    "samp_B = samp_B + np.random.uniform((B[0] - B[1])/2, (B[1] - B[0])/2, size = nsamp)\n",
    "ld50 = -samp_A / samp_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50bab766-3d75-475a-b5a3-e5e8d261984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samps = {'alpha': samp_A, 'beta': samp_B, 'LD50': ld50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74a18aa3-388f-4d2e-93b8-e7393791dde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           |    2.5%    |      97.5%      \n",
      "****************************************\n",
      "alpha      |   -0.56    |       3.67      \n",
      "beta       |    4.48    |      21.83      \n",
      "LD50       |   -0.17    |       0.13      \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n{:^10} | {:^10} | {:^16}\".format(\"\", \"2.5%\", \"97.5%\"))\n",
    "print(\"*\"*40)\n",
    "for k, v in samps.items():\n",
    "    print(\"{:<10} | {:^10} | {:^16}\".format(k, *np.round(np.quantile(v, q = [0.025, 0.975]), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251bb695-4c2d-49cc-acef-55ca2cae102b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
